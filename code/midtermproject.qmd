---
title: "Mid-term project instructions"
author: "Anish Bhattarai & Aleena Rayamajhi"
format:
  html:
    code-fold: false
    embed-resources: true
    toc: true
    number-sections: true
    theme: "cosmo"
---

# Mid-term project GitHub repository URL:  

Paste here the URL of the GitHub project (after going through the instruction steps)

# Instructions  
This file contains both the **instructions** for the mid-term project and placeholders for your code. You are required to use this file to produce code, output, and answers to the questions below.  

Besides simply creating output, make sure to interpret the output. You will need to create tables and/or plots to arrive at the answers, and then comment on what you found below it.    

To get you setup, you will need to:  

  - Student #1: create a repository on your GitHub account. You can call this repository "2024dsa_midproject_groupX", **where X is the number of your group**. Make it public, add a README, add a .gitignore for R.  
  - Student #1: follow the steps we did in class to start a new RStudio project with version control.  
  - Student #1: in your computer, create the sub-folders code, data, output, and move your data set into the `data` folder. Also, student 1 moves this current script into the `code` folder. Do a git stage, commit, push.  
  - Student #1: on GitHub, go the repository settings and invite your partner to be a collaborator in the repository. That will give them push permission.  
  - Now, both students should clone this repository on their computers like we did in class. Make sure this step works well and that you can pull and push from GitHub.  
  - Student 2, after cloning, does a git pull to get all these updates on their computer.  
  - Student 1 and 2 work together to update the README file. README files should explain what the repository is about, the goals of that project, who is working in it, and any other important details you may find.  
  
# Introduction  
Describe here the introduction of your problem. Consider this as a shortened version of your paper, where you will briefly discuss in 3-4 paragraphs what is the issue/gap in literature, and how the data you collected will help answer this gap.  

**Nitrogen (N) plays a critical role as a mineral nutrient essential for the growth and yield of cotton. Traditionally, Georgia cotton growers have relied on a standardized N application approach, which carries both benefits and limitations. While this method simplifies field management by applying a consistent dosage throughout the area, it fails to account for the inherent spatial and temporal variability within the field. Additionally, uncertainty persists regarding the optimal quantity of N fertilizer required each year, further complicating matters. To address these challenges, innovative strategies leveraging advanced sensor technology, variable-rate N applications, and real-time monitoring of crop N status have emerged as crucial solutions. We propose the utilization of sensors to identify N stress in cotton, allowing for the precise and timely management of in-season N requirement.  **

# Hypothesis and objectives  
Describe here your hypothesis, followed by your objectives. Make sure your hypothesis are testable and bold, and objectives are clear.  

*Hypothesis:* 
**Our hypothesis suggests that sensor-based variable-rate N applications can reduce the overall amount of N applied while maintaining equivalent yields, thereby enhancing partial profitability.**

*Objectives:*
**To contrast the effect of different side-dress fixed N rates and a sensor-based variable N rate on cotton yield, nitrogen use efficiency, and partial profit. ** 

# Material and Methods  
Describe here your overall material and methods as it pertains to the analysis you will conduct, including study description, site/setup description, what equipment was used, etc. just like you would in a paper. Make sure to clearly explain what was measured and how.

**The study was carried out in Midville, Georgia (33.72°N, 83.30°W) on an irrigated field where cotton was planted on May 25, 2023. Each experimental plot measured 9.14 m by 7.31 m (equivalent to 30 feet by 24 feet) and comprised of eight rows of cotton. The treatment design comprised a total of seven treatments including different side-dress N rates ranging from 0 to 128 kg N ha-1 and included one sensor-based treatment.** 

**The ACS-435 Crop Circle (Holland Scientific, Lincoln, NE), an active crop canopy sensor, was deployed for data collection and retrieval of NDRE index value from each plot. This index, obtained at the first square growth stage just before N application, involved handheld scanning of the third and fourth rows of each plot. Plot average NDRE values were then derived and used with the algorithm to determine plot-specific N rates which were then applied using a tractor-pulled sprayer. Each plot was individually harvested 170 days after planting. Cotton lint yield was determined after processing the samples by separating lint from seeds. **  

## Study design  
Clearly describe your study design here, including treatment design (which factors and levels, the hierarchy among them, etc.), and your experimental design (number of reps/blocks, how was randomization performed, etc.), as we talked about in class. 

 **The treatment design comprised different nitrogen rates with a total of seven treatments in the form of pre-plat and side dress 0 to 128 kg N ha-1. Out of 7 treatments there were one control, one variable rate treatment and rest five were fixed treatments. The variable rate treatment is also known as sensor-based treatment, as based on the sensor reading our N application rate was defined (Table 1).**
 
 **Similarly, as the experimental field was heterogeneous in nature so, randomized complete block design was performed with 4 replications/blocks. Restrictive randomization was performed for all 7 treatments within the block such that each treatment appear once in each replications. **

```{r include = F}
library(kableExtra)

treatment_lvl <- data.frame("Treatments" = c("0+0",
                                      "100+0",
                                      "36+24",
                                      "36+54",
                                      "36+84",
                                      "36+114",
                                      "36+VRN"
                                           ))
```

```{r echo = F}
kable(treatment_lvl,format = "html", col.names = "Treatment\n(pre-plant + side-dress)",
      align = "c", caption = "Table 1: Nitrogen application rates at preplant and side-dressing of cotton") %>% 
  kableExtra::kable_styling(full_width = F, font_size = 18, html_font = "sansserif", bootstrap_options = "striped", 
                            wraptable_width = "float", position = "center")
```


## Statistical analysis  
Describe here your statistical analysis, including what type of ANOVA model you ran (based on the design above), what was your response variable, what were your explanatory variables and how were the explanatory variables treated (random or fixed). Provide your alpha level. Explain which function from which package you used to analyze this data. Explain how you checked linear model assumptions and whether or not they were met. Overall, make sure you explain in sufficient detail that, if given your data, a knowledgeable person would be able to reproduce your analysis exactly.  

**The response variables of lint yield was analyzed with a mixed-effect analysis of variance (ANOVA) model utilizing R software (version 4.3.1). Different N rates were taken as fixed effect and block was taken as random effect. A significance level of α = 0.05 was used for determining significant terms in the ANOVA and for pairwise comparisons. lmer function from lme4 package was used to run the analysis.**

**Four different model assumptions were checked based on the residuals which are:**
**1. Residual Independence**
**2. Residual homoscadecity**
**3. Residual outliers**
**4. Residual normality**

# Results  
Here is where the coding is going to happen, and it will be completely up to you. Include under this section as many sub-sections (using ##) and as many chunks needed to create the analytical workflow for your analysis, starting at loading packages and data, wrangling, EDA, modeling, assumptions checking, ANOVA table, means, pairwise comparisons, and final publication-quality plot. 

Make sure to run a model that reflects your study design. Even if your study design does not include one of the designs covered in class, you are still expected to run the most appropriate model. If you need help for references, let me know.  

Before each chunk, describe the steps being performed in that chunk. For example, "Here I will load the data".  

If a chunk produces output, like printing a data frame, statistical summary, a plot, ANOVA table, etc., make sure to write text interpreting what you see and how you can/will use that information to move forward to the next steps in the workflow.  

## Setup

```{r setup, warning=FALSE, message=FALSE}
# Loading libraries
library(car) # for Anova function
library(dplyr) # wrangling
library(tidyr) # wrangling
library(tidyverse) # for data wrangling and plotting
library(ggplot2) # for plotting system for creating graphics
library(lme4) # to fit linear and generalized linear mixed-effects models
library(janitor) # to clean data
library(readxl) # import Excel files into R
library(emmeans) # for model mean extraction
library(multcomp) # for pairwise comparison letter display
library(broom.mixed) # summarize mixed models and extract residuals
library(ggpmisc) # extensions and utilities for ggplot2
#install.packages("shadowtext")
library(shadowtext) # create shadowed text for visualizations
```

```{r include = F}
knitr::opts_chunk$set(message = F, warning = F)

my_theme <- theme(plot.background = element_blank(),
                  panel.background = element_rect(fill = "gray80"),
                  panel.grid = element_blank(),
                  plot.title = element_text(hjust = 0.5, size = 18))
```


## Importing Data
```{r data import}
yield_mid <- read_xlsx("../data/Yield Midville.xlsx") %>% 
  clean_names()

info_mid <- read_csv("../data/info_mid_all_rates.csv") %>% 
  rename(plots = plot_ids)

ginning_pct <- read_xlsx("../data/Midville ginning percentage 2023.xlsx")[-1,] %>% 
  clean_names() %>% 
  dplyr::select(plots, gt)
```


## EDA Tables
```{r}
summary(yield_mid)
```

```{r}
glimpse(yield_mid)
```

## Data Merging and Wrangling
```{r}
yield_mid_merged <- yield_mid %>% 
  merge(info_mid, by = "plots") %>% 
  dplyr::select(plots, treatment, yield_kg, blocks, total_lbac) %>% 
  mutate(plot_yield_kg = yield_kg*4,
         kgsqft = plot_yield_kg/720,
         kgsqm = kgsqft/0.092903,
         kgha = kgsqm*10000) %>% 
  mutate_at(.vars = c("treatment", "blocks"), .funs = factor) %>% 
  mutate(treatment = factor(treatment,levels = c("0+0",
                                      "100+0",
                                      "36+24",
                                      "36+54",
                                      "36+84",
                                      "36+114",
                                      "36+VRN")))

head(yield_mid_merged, 6)
```

```{r}
glimpse(yield_mid_merged)
```
## Lint yield calculation

```{r}
# Lint yield is the total fiber yield of the cotton after the seed are removed and the process is known as ginning.

lint_yield <- yield_mid_merged %>% 
  merge(ginning_pct, by = "plots") %>% 
  mutate(lint_kgha = kgha*gt) %>% 
  dplyr::select(plots, treatment, blocks, lint_kgha, total_lbac)
```

```{r}
lint_yield %>% 
  ggplot()+
  geom_density(aes(x = lint_kgha), fill = "red", alpha = 0.4)+
  labs(x = "Lint Yield (kg/ha)",
       y = "Density")+
  my_theme
```

##Statistical Model
```{r}
model <- lmer(lint_kgha ~ treatment + (1|blocks), data = lint_yield)

summary(model)
```

```{r}
Anova(model, type = 3)
```

```{r}
emmeans <- emmeans(model, ~treatment)

pwc <- cld(emmeans, adjust = "none",
           reversed = T, Letters = letters) %>% 
  as.data.frame() %>% 
  mutate(letters = trimws(.group))
```

```{r}
lint_yield %>% 
  ggplot()+
  geom_boxplot(aes(x = treatment, y = lint_kgha, fill = treatment), outlier.shape = NA, alpha = 0.7)+
  geom_point(data = pwc, aes(x = treatment, y = emmean, color = treatment))+
  geom_shadowtext(data = pwc, aes(x = treatment, y = emmean , label = letters),show.legend = F, bg = "black",  color = "white", size = 4.5)+
  labs(x = expression(bold(paste("Treatments (kg ha"^-1, ")"))),
       y = expression(bold(paste("Lint Yield (kg ha"^-1, ")"))),
       fill = "Treatments",
       title = "Lint Yield Affected by N Treatments in\n Midville")+
  theme_gray()+
  scale_x_discrete(labels = c("0+0",
                              "112+0",
                              "40+26",
                              "40+60",
                              "40+94",
                              "40+128",
                              "40+VRN"))+
  scale_fill_brewer(type = "seq", palette = "YlOrBr")+
  scale_y_continuous(breaks = seq(500, 3000, 250))+
  guides(color = F, fill = F)+
  theme(panel.background = element_rect(fill = "gray80"),
        panel.grid = element_blank(),
        legend.position = c(0.075, 0.82),
        legend.background = element_rect(fill = "gray88"),
        legend.key.height = unit(5.5, "mm"),
        axis.title = element_text(size = 14),
        plot.title = element_text(size = 20, face = "bold", hjust = 0.5))

ggsave("../output/midville_lint_yield.png",
       height = 6, 
       width = 8)
```

##Interpretation: 

# Team work in GitHub  
Whether you are working with your future-self or as duos, make sure to stage, commit, and push after finishing each of the sub-sections above. When committing, write commit messages that are short and descriptive (e.g., finished wrangling).  

If you are working in duos, make sure to split the workload. I will check your collaborative work through the commit history, and if one student has contributed significantly more than the other, than that will impact grades.  

**Tip 1**: to avoid merge conflicts, make sure to **pull** first, and then start working locally. That will ensure that any changes made by your partner will be "downloaded" before you make changes to the files locally.  

**Tip 2**: make use of the Issues on this repository to set up to-do lists and assign tasks to different people. You can also use each issue/task to discuss how things should be run and get to an agreement.  

# Submitting your work  
Once you have developed all the code and answers, make sure to Render this quarto file.  

**Notes on rendering**:  

- Make sure to render your work and inspect how the final html look like.  
- If it does not look professional for whatever reason, then fix the issue, re-render it, recheck.  
- Only send me your work once your html file looks professional.  
- Some potential issues you may encounter and how to fix them:   
  - Some times your code may be creating a table output that is waaay to long and cumbersome to scroll through when rendered. If this is the case, make it more professional looking by using the `head()` function to only print the first handful of rows (instead of thousands of rows).  
  
  - **DO NOT** delete the file's heading levels (# and ##). They set up the proper heading 1 and 2 levels, and I use them to guide my grading.  
  
  - If a given chunk is also outputting warnings or messages, inhibit this behavior by changing the chunk options `message` and `warning` to `FALSE`.  
  
  - If, after rendered, 2 lines of text are connected and you wish to "break line" between them, add 2 extra spaces after the first one.  

After rendering, an .html file will be created on your `code` folder.  

Rename this file to `LASTNAME1-LASTNAME2_midtermproject.html`.    
For ex., `Bastos-Mendes_midtermproject.html`.

Send the html file to my email (lmbastos@uga.edu) by **April 11th** 11:59 pm.  













  

  

